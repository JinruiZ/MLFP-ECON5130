{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Input and output\n",
    "\n",
    "In this unit we discuss input and output,\n",
    "or I/O for short. In doing so, we focus exclusively on I/O\n",
    "routines used to load and store data from files that are relevant\n",
    "for numerical computation and data analysis.\n",
    "\n",
    "## I/O with NumPy\n",
    "\n",
    "We have already encountered the most basic, and probably most frequently used\n",
    "NumPy I/O routine, `np.loadtxt()`. The most important I/O functions to\n",
    "process text data are:\n",
    "\n",
    "-   `loadtxt()`: load data from a text file.\n",
    "-   `genfromtxt()`: load data from a text file and handle missing\n",
    "    data and heterogenous data.\n",
    "-   `savetxt()`: save a NumPy array to a text file.\n",
    "\n",
    "There are a few other I/O functions in NumPy, for example to\n",
    "write arrays as raw binary data.\n",
    "These are listed in the [official documentation](https://numpy.org/doc/stable/reference/routines.io.html).\n",
    "\n",
    "We frequently use files that store data\n",
    "as character-separated values (CSV) in pure text format since virtually\n",
    "and application supports this data format.\n",
    "Imagine we have the following tabular data from [FRED](https://fred.stlouisfed.org/)\n",
    "which we already used in the first unit, where the first two rows\n",
    "look as follows:\n",
    "\n",
    "| Year |  GDP   |  CPI | UNRATE |\n",
    "| ---- | ------ | ---- | ------ |\n",
    "| 1948 | 2118.5 | 24.0 | 3.8    |\n",
    "| 1949 | 2106.6 | 23.8 | 6.0    |\n",
    "\n",
    "To load a CSV file as a NumPy array, we use `loadtxt()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1948. , 2118.5,   24. ,    3.8],\n       [1949. , 2106.6,   23.8,    6. ]])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# load CSV\n",
    "data = np.loadtxt('../data/FRED.csv', skiprows=1, delimiter=',')\n",
    "data[:2]        # Display first two rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default settings will in many cases be appropriate to load\n",
    "whatever CSV file you might have. However, you'll occasionally\n",
    "want to specify the following arguments to override the defaults:\n",
    "\n",
    "-   `delimiter`: Character used to separate individual fields (default: space)\n",
    "-   `skiprows=n`: Skip the first `n` rows. For example, if the CSV file\n",
    "    contains a header with variable names, `skiprows=1` needs to be\n",
    "    specified as NumPy by default cannot process these names.\n",
    "-   `dtype`: Enforce a particular data type for the resulting array.\n",
    "-   `encoding`: Set the character encoding of the input data. This\n",
    "    is usually not needed, but can be required to import data\n",
    "    with non-latin characters that are not encoded using Unicode.\n",
    "\n",
    "NumPy implements an additional function to load text data,\n",
    "`np.genfromtxt()`. This routine is more flexible: among other things, it can handle\n",
    "missing values, or data that mixes strings and numerical values.\n",
    "\n",
    "For example, when we try to load our sample of universities with\n",
    "`loadtxt()`, we get the following error:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\"University of Glasgow\"'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-37-26b757ebcd56>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m# Try to load CSV data that contains strings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# This will result in an error!\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m';'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskiprows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001B[0m\n\u001B[1;32m   1137\u001B[0m         \u001B[0;31m# converting the data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1139\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_loadtxt_chunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1140\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mread_data\u001B[0;34m(chunk_size)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mfloatconv\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    761\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'0x'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    762\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromhex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 763\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    764\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    765\u001B[0m     \u001B[0mtyp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: '\"University of Glasgow\"'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "filename = '../data/universities.csv'\n",
    "# Try to load CSV data that contains strings\n",
    "# This will result in an error!\n",
    "data = np.loadtxt(filename, delimiter=';', skiprows=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code fails for two reasons:\n",
    "\n",
    "1.  The file contains strings and floats, and `loadtxt()` by default\n",
    "    cannot load mixed data.\n",
    "2.  There are missing values (empty fields), which `loadtxt()` cannot\n",
    "    handle either.\n",
    "\n",
    "We can address the first issue by creating a so-called\n",
    "[structured array](https://numpy.org/doc/stable/user/basics.rec.html),\n",
    "ie. an array that contains fields with mixed data.\n",
    "This is accomplished by constructing a special `dtype` that\n",
    "specifies the field names and their data types:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-679bfdb9f8bd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m                    \u001B[0;34m(\u001B[0m\u001B[0;34m'Founded'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'i4'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'Students'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'i4'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                    ('Budget', 'f8'), ('Ranking', 'i4')])\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m';'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskiprows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001B[0m\n\u001B[1;32m   1137\u001B[0m         \u001B[0;31m# converting the data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1139\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_loadtxt_chunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1140\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mread_data\u001B[0;34m(chunk_size)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.7/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mfloatconv\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    761\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'0x'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    762\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromhex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 763\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    764\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    765\u001B[0m     \u001B[0mtyp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: "
     ]
    }
   ],
   "source": [
    "# Define names and data types for fields in CSV file\n",
    "dtypes = np.dtype([('Institution', 'U30'), ('Country', 'U20'),\n",
    "                   ('Founded', 'i4'), ('Students', 'i4'),\n",
    "                   ('Budget', 'f8'), ('Ranking', 'i4')])\n",
    "data = np.loadtxt(filename, delimiter=';', skiprows=1, dtype=dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, this still fails because the budget for Swansea University\n",
    "is missing.\n",
    "\n",
    "We can get around this by using `genfromtxt()` which assigns the\n",
    "`np.nan` to missing values:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "('\"Swansea University\"', '\"Wales\"', 1920, 20620, nan, 251)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt(filename, delimiter=';', dtype=dtypes, encoding='utf8')\n",
    "data[-1]        # print last observation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the CSV file can now be processed without errors, you see that\n",
    "NumPy does not remove the double quotes around strings such as the\n",
    "university name.\n",
    "\n",
    "Instead of trying to fix this, it is advisable to just use pandas to\n",
    "load this kind of data which handles all these problems automatically.\n",
    "We examine this alternative below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, to save a NumPy array to a CSV file, there is a logical counterpart\n",
    "to `np.loadtxt()` which is called `np.savetxt()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving CSV file to /tmp/tmp183znwz6/data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import tempfile\n",
    "\n",
    "# Generate some random data on [0,1)\n",
    "data = np.random.default_rng(123).random(size=(10, 5))\n",
    "\n",
    "# create temporary directory\n",
    "d = tempfile.TemporaryDirectory()\n",
    "# CSV file name\n",
    "filename = os.path.join(d.name, 'data.csv')\n",
    "\n",
    "# Print destination file - this will be different each time\n",
    "print(f'Saving CSV file to {filename}')\n",
    "\n",
    "# Write NumPy array to CSV file\n",
    "np.savetxt(filename, data, delimiter=';', fmt='%8.5f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above code creates a $10 \\times 5$ matrix of random floats\n",
    "and stores these in the file `data.csv` using 5 significant digits.\n",
    "The destination file is located in a temporary directory which\n",
    "will be different every time this code is run.\n",
    "We use the `tempfile` module to create this writeable temporary\n",
    "directory.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## I/O with pandas\n",
    "\n",
    "Pandas's I/O routines are more powerful than those implemented in NumPy:\n",
    "\n",
    "-   It supports reading and writing numerous file formats.\n",
    "-   It supports heterogeneous data without having to specify\n",
    "    the data type in advance.\n",
    "-   It gracefully handles missing values.\n",
    "\n",
    "For these reasons, it is often preferrable to directly use pandas to\n",
    "process data instead of NumPy.\n",
    "\n",
    "The most important routines are:\n",
    "\n",
    "-   `read_csv()`, `to_csv()`: Read or write CSV text files\n",
    "-   `read_fwf()`: Read data with fixed field width, ie. text data\n",
    "    that does not use delimiters to separate fields.\n",
    "-   `read_excel()`, `to_excel()`: Read or write Excel spreadsheets\n",
    "-   `read_stata()`, `to_stata()`: Rear or write Stata's `.dta` files.\n",
    "\n",
    "For a complete list of I/O routines, see the [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).\n",
    "\n",
    "To illustrate, we repeat the above example using pandas's\n",
    "`read_csv()`. Since this file contains only floating-point\n",
    "data, the result is very similar to reading in a NumPy array."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year     GDP   CPI  UNRATE\n0  1948  2118.5  24.0     3.8\n1  1949  2106.6  23.8     6.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>GDP</th>\n      <th>CPI</th>\n      <th>UNRATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1948</td>\n      <td>2118.5</td>\n      <td>24.0</td>\n      <td>3.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1949</td>\n      <td>2106.6</td>\n      <td>23.8</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = '../data/FRED.csv'\n",
    "df = pd.read_csv(filename, sep=',')\n",
    "df.head(2)          # Display the first 2 rows of data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference between NumPy and pandas become obvious when we\n",
    "try to load our university data: this works out of the box,\n",
    "without the need to specify any data types:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "                   Institution           Country  Founded  Students  Budget  \\\n20      University of Stirling          Scotland     1967      9548   113.3   \n21  Queen’s University Belfast  Northern Ireland     1810     18438   369.2   \n22          Swansea University             Wales     1920     20620     NaN   \n\n    Rank  \n20   301  \n21   200  \n22   251  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Institution</th>\n      <th>Country</th>\n      <th>Founded</th>\n      <th>Students</th>\n      <th>Budget</th>\n      <th>Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>University of Stirling</td>\n      <td>Scotland</td>\n      <td>1967</td>\n      <td>9548</td>\n      <td>113.3</td>\n      <td>301</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Queen’s University Belfast</td>\n      <td>Northern Ireland</td>\n      <td>1810</td>\n      <td>18438</td>\n      <td>369.2</td>\n      <td>200</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Swansea University</td>\n      <td>Wales</td>\n      <td>1920</td>\n      <td>20620</td>\n      <td>NaN</td>\n      <td>251</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = '../data/universities.csv'\n",
    "df = pd.read_csv(filename, sep=';')\n",
    "df.tail(3)      # show last 3 rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that missing values are correctly converted to `np.nan` and\n",
    "the double quotes surrounding strings are automatically removed!\n",
    "\n",
    "\n",
    "Unlike NumPy, pandas can also process other popular data formats\n",
    "such as MS Excel files (or OpenDocument spreadsheets):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "                Institution   Country  Founded  Students  Budget  Rank\n0     University of Glasgow  Scotland     1451     30805   626.5    92\n1   University of Edinburgh  Scotland     1583     34275  1102.0    30\n2  University of St Andrews  Scotland     1413      8984   251.2   201",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Institution</th>\n      <th>Country</th>\n      <th>Founded</th>\n      <th>Students</th>\n      <th>Budget</th>\n      <th>Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>University of Glasgow</td>\n      <td>Scotland</td>\n      <td>1451</td>\n      <td>30805</td>\n      <td>626.5</td>\n      <td>92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>University of Edinburgh</td>\n      <td>Scotland</td>\n      <td>1583</td>\n      <td>34275</td>\n      <td>1102.0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>University of St Andrews</td>\n      <td>Scotland</td>\n      <td>1413</td>\n      <td>8984</td>\n      <td>251.2</td>\n      <td>201</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Excel file containing university data\n",
    "filename = '../data/../data/universities.xlsx'\n",
    "\n",
    "df = pd.read_excel(filename, sheet_name='universities')\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The routine `read_excel()` takes the argument `sheet_name` to\n",
    "specify the sheet that should be read.\n",
    "\n",
    "-   Note that the Python package `xlrd` needs to be installed in order\n",
    "    to read files from Excel 2003 and above.\n",
    "\n",
    "Finally, we often encounter text files with fixed field widths,\n",
    "since this is a commonly used format in older applications\n",
    "(for example, fixed-width files are easy to create in Fortran).\n",
    "To read such files, the width (ie. the number of characters)\n",
    "has to be explicitly specified:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "   Year     GDP   CPI  UNRATE\n0  1948  2118.5  24.0     3.8\n1  1949  2106.6  23.8     6.0\n2  1950  2289.5  24.1     5.2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>GDP</th>\n      <th>CPI</th>\n      <th>UNRATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1948</td>\n      <td>2118.5</td>\n      <td>24.0</td>\n      <td>3.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1949</td>\n      <td>2106.6</td>\n      <td>23.8</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950</td>\n      <td>2289.5</td>\n      <td>24.1</td>\n      <td>5.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File name of FRED data, stored as fixed-width text\n",
    "filename = '../data/FRED-fixed.csv'\n",
    "\n",
    "# field widths are passed as list to read_fwf()\n",
    "df = pd.read_fwf(filename, widths=[5, 7, 5, 8])\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the `widths` argument accepts a list that contains the\n",
    "number of characters to be used for each field."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Pickling\n",
    "\n",
    "A wholly different approach to data I/O is taken by Python's\n",
    "built-in `pickle` module (see [official documentation](https://docs.python.org/3/library/pickle.html)).\n",
    "Almost any Python object can be\n",
    "dumped into a binary file and read back using `pickle.dump()`\n",
    "and `pickle.load()`.\n",
    "\n",
    "The big advantage over other methods\n",
    "is that hierarchies of objects are automatically supported.\n",
    "For example, we can pickle a list containing a `tuple`, a string and a NumPy array:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickled data written to /tmp/tmph3baf593/data.bin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tempfile\n",
    "import os.path\n",
    "\n",
    "# Generate some random data on [0,1)\n",
    "arr = np.arange(10).reshape((2, -1))\n",
    "tpl = (1, 2, 3)\n",
    "text = 'Pickle is very powerful!'\n",
    "\n",
    "# data: several nested containers and strings\n",
    "data = [tpl, text, arr]\n",
    "\n",
    "# create temporary directory\n",
    "d = tempfile.TemporaryDirectory()\n",
    "# Binary destination file\n",
    "filename = os.path.join(d.name, 'data.bin')\n",
    "\n",
    "# print destination file path\n",
    "print(f'Pickled data written to {filename}')\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then read back the data as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 1, 2, 3, 4],\n       [5, 6, 7, 8, 9]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pickle data from above\n",
    "with open(filename, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# expand data into its components\n",
    "tpl, text, arr = data\n",
    "arr         # prints previously generated array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above example introduces a few concepts we have not countered so far:\n",
    "\n",
    "1.  The built-in function `open()` is used to open files for\n",
    "    reading or writing.\n",
    "\n",
    "    -   The second argument indicates whether\n",
    "        a file should be read-only, `r`, or writeable, `w`.\n",
    "    -   The `b` sets the file mode to *binary*, ie. its contents are not\n",
    "        human-readable text.\n",
    "\n",
    "2.  We usually access files using a so-called *context manager*.\n",
    "    A context manager is created via the `with` statement.\n",
    "\n",
    "    A big advantage of using a context manager is that the\n",
    "    file resource made available as `f` in the block following\n",
    "    `with` is automatically cleaned up as soon as the block exits.\n",
    "    This is particularly important when writing data.\n",
    "\n",
    "So why not always use `pickle` to load and store data?\n",
    "\n",
    "1.  Pickling is Python-specific and no other application can process\n",
    "    pickled data.\n",
    "2.  The pickle protocol can change in a newer version of Python,\n",
    "    and you might not be able to read back your old pickled objects.\n",
    "3.  Even worse, because projects such as NumPy and pandas implement\n",
    "    their own pickling routines, you might not even be able\n",
    "    to unpickle old DataFrames when you upgrade to a newer pandas version!\n",
    "4.  `pickle` is not secure: It is possible to construct binary\n",
    "    data that will execute arbitrary code when unpickling, so you\n",
    "    don't want to unpickle data from untrusted sources.\n",
    "5.  Some object cannot be pickled automatically.\n",
    "    For example, this applies to\n",
    "    any classes defined with Numba or Cython, unless special care\n",
    "    is taken to implement the pickle protocol.\n",
    "\n",
    "\n",
    "`pickle` is great for internal use when you do not need to exchange\n",
    "data with others and have complete control over your computing environment\n",
    "(ie. you can enforce a specific version of Python and the libraries you are\n",
    "using). For anything else, you should avoid it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b08fdce2",
   "language": "python",
   "display_name": "PyCharm (python-statistics)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}