{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data input and output\n",
    "\n",
    "In this unit we discuss input and output,\n",
    "or I/O for short. We focus exclusively on I/O\n",
    "routines used to load and store data from files that are relevant\n",
    "for numerical computation and data analysis."
   ]
  },
  {
   "source": [
    "## I/O with NumPy\n",
    "\n",
    "We have already encountered the most basic, and probably most frequently used\n",
    "NumPy I/O routine, `np.loadtxt()`.\n",
    "We often use files that store data\n",
    "as text files containing character-separated values (CSV) since virtually\n",
    "any application supports this data format.\n",
    "The most important I/O functions to process text data are:\n",
    "\n",
    "-   [`np.loadtxt()`](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html):     load data from a text file.\n",
    "-   [`np.genfromtxt()`](https://numpy.org/doc/stable/reference/generated/numpy.genfromtxt.html): \n",
    "    load data from a text file and handle missing data.\n",
    "-   [`np.savetxt()`](https://numpy.org/doc/stable/reference/generated/numpy.savetxt.html): \n",
    "    save a NumPy array to a text file.\n",
    "\n",
    "There are a few other I/O functions in NumPy, for example to\n",
    "write arrays as raw binary data.\n",
    "We won't cover them here, but you can find them in the\n",
    "[official documentation](https://numpy.org/doc/stable/reference/routines.io.html).\n",
    "\n",
    "Imagine we have the following tabular data from [FRED](https://fred.stlouisfed.org/)\n",
    "which we already used in the first unit, where the first two rows\n",
    "look as follows:\n",
    "\n",
    "| Year |  GDP   |  CPI | UNRATE |\n",
    "| ---- | ------ | ---- | ------ |\n",
    "| 1948 | 2118.5 | 24.0 | 3.8    |\n",
    "| 1949 | 2106.6 | 23.8 | 6.0    |\n",
    "\n",
    "To load this CSV file as a NumPy array, we use `loadtxt()`:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1948. , 2118.5,   24. ,    3.8],\n",
       "       [1949. , 2106.6,   23.8,    6. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# relative path to CSV file\n",
    "file = '../data/FRED.csv'\n",
    "\n",
    "# load CSV\n",
    "data = np.loadtxt(file, skiprows=1, delimiter=',')\n",
    "data[:2]        # Display first two rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The default settings will in many cases be appropriate to load\n",
    "whatever CSV file we might have. However, we'll occasionally\n",
    "want to specify the following arguments to override the defaults:\n",
    "\n",
    "-   `delimiter`: Character used to separate individual fields (default: space).\n",
    "-   `skiprows=n`: Skip the first `n` rows. For example, if the CSV file\n",
    "    contains a header with variable names, `skiprows=1` needs to be\n",
    "    specified as NumPy by default cannot process these names.\n",
    "-   `dtype`: Enforce a particular data type for the resulting array.\n",
    "-   `encoding`: Set the character encoding of the input data. This\n",
    "    is usually not needed, but can be required to import data\n",
    "    with non-latin characters that are not encoded using Unicode.\n",
    "\n",
    "While `loadtxt()` is simple to use, it quickly reaches its limits\n",
    "with more complex data sets.\n",
    "For example, when we try to load our sample of universities with\n",
    "`loadtxt()`, we get the following error:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\"University of Glasgow\"'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-b1ec39e83237>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# Try to load CSV data that contains strings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;31m# This will result in an error!\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m';'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskiprows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001B[0m\n\u001B[1;32m   1137\u001B[0m         \u001B[0;31m# converting the data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1139\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_loadtxt_chunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1140\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mread_data\u001B[0;34m(chunk_size)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mfloatconv\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    761\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'0x'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    762\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfromhex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 763\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    764\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    765\u001B[0m     \u001B[0mtyp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: '\"University of Glasgow\"'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "file = '../data/universities.csv'\n",
    "\n",
    "# Try to load CSV data that contains strings\n",
    "# This will result in an error!\n",
    "data = np.loadtxt(file, delimiter=';', skiprows=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This code fails for two reasons:\n",
    "\n",
    "1.  The file contains strings and floats, and `loadtxt()` by default\n",
    "    cannot load mixed data.\n",
    "2.  There are missing values (empty fields), which `loadtxt()` cannot\n",
    "    handle either.\n",
    "\n",
    "We can address the first issue by creating a so-called\n",
    "[structured array](https://numpy.org/doc/stable/user/basics.rec.html),\n",
    "i.e. an array that contains fields with mixed data.\n",
    "This is accomplished by constructing a special `dtype` object that\n",
    "specifies the field names and their data types:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-6782620dfdeb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m                    ('Budget', 'f8')])           # float, 8 bytes\n\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloadtxt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdelimiter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m';'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mskiprows\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtypes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mloadtxt\u001B[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001B[0m\n\u001B[1;32m   1137\u001B[0m         \u001B[0;31m# converting the data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1138\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1139\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mread_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_loadtxt_chunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1140\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mX\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m                 \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36mread_data\u001B[0;34m(chunk_size)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m   1065\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1066\u001B[0m             \u001B[0;31m# Convert each value according to its column and store\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1067\u001B[0;31m             \u001B[0mitems\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconverters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1068\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m             \u001B[0;31m# Then pack it according to the dtype's nesting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.conda/envs/py3-default/lib/python3.8/site-packages/numpy/lib/npyio.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    771\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    772\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtyp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0minteger\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 773\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    774\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0missubclass\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtyp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlongdouble\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    775\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlongdouble\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "# Define names and data types for fields in CSV file\n",
    "#   Data types are defined using two tokens:\n",
    "#       1.  The main data type (U: unicode string, f: float, i: integer)\n",
    "#       2.  The precision or field width\n",
    "dtypes = np.dtype([('Institution', 'U30'),      # unicode string of length 30\n",
    "                   ('Country', 'U20'),          # unicode string of length 20\n",
    "                   ('Founded', 'i4'),           # integer, 4 bytes\n",
    "                   ('Students', 'i4'),\n",
    "                   ('Staff', 'i4'),\n",
    "                   ('Admin', 'i4'),\n",
    "                   ('Budget', 'f8')])           # float, 8 bytes\n",
    "\n",
    "data = np.loadtxt(file, delimiter=';', skiprows=1, dtype=dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, this still fails because the of a few missing values.\n",
    "\n",
    "We can get around this by using `genfromtxt()`, which is\n",
    "more flexible and can also deal with missing data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([('\"University of Strathclyde\"', '\"Scotland\"', 1964, 22640,   -1, 3200,  304.4),\n",
       "       ('\"University of Oxford\"', '\"England\"', 1096, 24515, 7000,   -1, 2450. ),\n",
       "       ('\"University of Manchester\"', '\"England\"', 2004, 40250, 3849,   -1, 1095.4),\n",
       "       ('\"University of Birmingham\"', '\"England\"', 1825, 35445, 4020,   -1,  673.8),\n",
       "       ('\"University of Nottingham\"', '\"England\"', 1798, 30798, 3495,   -1,  656.5),\n",
       "       ('\"University of Stirling\"', '\"Scotland\"', 1967,  9548,   -1, 1872,  113.3),\n",
       "       ('\"Swansea University\"', '\"Wales\"', 1920, 20620,   -1, 3290,    nan)],\n",
       "      dtype=[('Institution', '<U30'), ('Country', '<U20'), ('Founded', '<i4'), ('Students', '<i4'), ('Staff', '<i4'), ('Admin', '<i4'), ('Budget', '<f8')])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# load data using genfromtxt()\n",
    "# We still need to specify the dtype defined above!\n",
    "data = np.genfromtxt(file, delimiter=';', dtype=dtypes, encoding='utf8',\n",
    "                     skip_header=1)\n",
    "\n",
    "# Determine rows with missing data:\n",
    "#   - missing integers are coded as -1\n",
    "#   - missing floats are coded as np.nan\n",
    "missing = (data['Staff'] < 0) | (data['Admin'] < 0) | np.isnan(data['Budget'])\n",
    "\n",
    "# print rows with missing values\n",
    "data[missing]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the CSV file can now be processed without errors, you see that\n",
    "NumPy does not remove the double quotes around strings such as the\n",
    "university names.\n",
    "Instead of trying to fix this, it is advisable to just use pandas to\n",
    "load this kind of data which handles all these problems automatically.\n",
    "We examine this alternative below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, to save a NumPy array to a CSV file, there is a logical counterpart\n",
    "to `np.loadtxt()` which is called `np.savetxt()`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving CSV file to /tmp/tmp8rcc7foi/data.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import tempfile\n",
    "\n",
    "# Generate some random data on [0,1)\n",
    "data = np.random.default_rng(123).random(size=(10, 5))\n",
    "\n",
    "# create temporary directory\n",
    "d = tempfile.TemporaryDirectory()\n",
    "\n",
    "# path to CSV file\n",
    "file = os.path.join(d.name, 'data.csv')\n",
    "\n",
    "# Print destination file - this will be different each time\n",
    "print(f'Saving CSV file to {file}')\n",
    "\n",
    "# Write NumPy array to CSV file\n",
    "np.savetxt(file, data, delimiter=';', fmt='%8.5f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above code creates a $10 \\times 5$ matrix of random floats\n",
    "and stores these in the file `data.csv` using 5 significant digits.\n",
    "\n",
    "We store the destination file in a temporary directory which\n",
    "we create as follows:\n",
    "\n",
    "-   Because we cannot know in advance on which system this code\n",
    "    is run (e.g. the operating system and directory layout),\n",
    "    we cannot hard-code a file path.\n",
    "-   Moreover, we do not know whether the code is run with write\n",
    "    permissions in any particular folder.\n",
    "-   We work around this issue by asking the Python runtime to\n",
    "    create a writeable temporary directory *for the system\n",
    "    where the code is being run*.\n",
    "-   We use the routines in the \n",
    "    [`tempfile`](https://docs.python.org/3/library/tempfile.html) \n",
    "    module to create this temporary directory.\n",
    "\n",
    "Of course, on your own computer you do not need to use a temporary\n",
    "directory, but can instead use any directory where\n",
    "your user has write permissions. For example, on Windows you\n",
    "could use something along the lines of\n",
    "\n",
    "    file = 'C:/Users/Path/to/file.txt'\n",
    "    np.savetxt(file, data, delimiter=';', fmt='%8.5f')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## I/O with pandas\n",
    "\n",
    "Pandas's I/O routines are more powerful than those implemented in NumPy:\n",
    "\n",
    "-   They support reading and writing numerous file formats.\n",
    "-   They support heterogeneous data without having to specify\n",
    "    the data type in advance.\n",
    "-   They gracefully handle missing values.\n",
    "\n",
    "For these reasons, it is often preferable to directly use pandas to\n",
    "process data instead of NumPy.\n",
    "\n",
    "The most important routines are:\n",
    "\n",
    "-   [`read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html), \n",
    "    [`to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html): \n",
    "    Read or write CSV text files\n",
    "-   [`read_fwf()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_fwf.html): \n",
    "    Read data with fixed field widths, i.e. text data\n",
    "    that does not use delimiters to separate fields.\n",
    "-   [`read_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html), \n",
    "    [`to_excel()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html): \n",
    "    Read or write Excel spreadsheets\n",
    "-   [`read_stata()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_stata.html), \n",
    "    [`to_stata()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_stata.html): \n",
    "    Read or write Stata's `.dta` files.\n",
    "\n",
    "For a complete list of I/O routines, see the [official documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html).\n",
    "\n",
    "To illustrate, we repeat the above examples using pandas's\n",
    "`read_csv()`. Since the FRED data contains only floating-point\n",
    "data, the result is very similar to reading in a NumPy array."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Year     GDP   CPI  UNRATE\n",
       "0  1948  2118.5  24.0     3.8\n",
       "1  1949  2106.6  23.8     6.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>GDP</th>\n      <th>CPI</th>\n      <th>UNRATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1948</td>\n      <td>2118.5</td>\n      <td>24.0</td>\n      <td>3.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1949</td>\n      <td>2106.6</td>\n      <td>23.8</td>\n      <td>6.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# relative path to CSV file\n",
    "file = '../data/FRED.csv'\n",
    "\n",
    "df = pd.read_csv(file, sep=',')\n",
    "df.head(2)          # Display the first 2 rows of data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The difference between NumPy and pandas become obvious when we\n",
    "try to load our university data: this works out of the box,\n",
    "without the need to specify any data types or to handle missing values:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   Institution           Country  Founded  Students   Staff  \\\n",
       "20      University of Stirling          Scotland     1967      9548     NaN   \n",
       "21  Queen’s University Belfast  Northern Ireland     1810     18438  2414.0   \n",
       "22          Swansea University             Wales     1920     20620     NaN   \n",
       "\n",
       "     Admin  Budget  Russell  \n",
       "20  1872.0   113.3        0  \n",
       "21  1489.0   369.2        1  \n",
       "22  3290.0     NaN        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Institution</th>\n      <th>Country</th>\n      <th>Founded</th>\n      <th>Students</th>\n      <th>Staff</th>\n      <th>Admin</th>\n      <th>Budget</th>\n      <th>Russell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>University of Stirling</td>\n      <td>Scotland</td>\n      <td>1967</td>\n      <td>9548</td>\n      <td>NaN</td>\n      <td>1872.0</td>\n      <td>113.3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Queen’s University Belfast</td>\n      <td>Northern Ireland</td>\n      <td>1810</td>\n      <td>18438</td>\n      <td>2414.0</td>\n      <td>1489.0</td>\n      <td>369.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Swansea University</td>\n      <td>Wales</td>\n      <td>1920</td>\n      <td>20620</td>\n      <td>NaN</td>\n      <td>3290.0</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# relative path to CSV file\n",
    "file = '../data/universities.csv'\n",
    "\n",
    "df = pd.read_csv(file, sep=';')\n",
    "df.tail(3)      # show last 3 rows"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note that missing values are correctly converted to `np.nan` and\n",
    "the double quotes surrounding strings are automatically removed!\n",
    "\n",
    "\n",
    "Unlike NumPy, pandas can also process other popular data formats\n",
    "such as MS Excel files (or OpenDocument spreadsheets):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Institution   Country  Founded  Students   Staff   Admin  \\\n",
       "0     University of Glasgow  Scotland     1451     30805  2942.0  4003.0   \n",
       "1   University of Edinburgh  Scotland     1583     34275  4589.0  6107.0   \n",
       "2  University of St Andrews  Scotland     1413      8984  1137.0  1576.0   \n",
       "\n",
       "   Budget  Russell  \n",
       "0   626.5        1  \n",
       "1  1102.0        1  \n",
       "2   251.2        0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Institution</th>\n      <th>Country</th>\n      <th>Founded</th>\n      <th>Students</th>\n      <th>Staff</th>\n      <th>Admin</th>\n      <th>Budget</th>\n      <th>Russell</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>University of Glasgow</td>\n      <td>Scotland</td>\n      <td>1451</td>\n      <td>30805</td>\n      <td>2942.0</td>\n      <td>4003.0</td>\n      <td>626.5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>University of Edinburgh</td>\n      <td>Scotland</td>\n      <td>1583</td>\n      <td>34275</td>\n      <td>4589.0</td>\n      <td>6107.0</td>\n      <td>1102.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>University of St Andrews</td>\n      <td>Scotland</td>\n      <td>1413</td>\n      <td>8984</td>\n      <td>1137.0</td>\n      <td>1576.0</td>\n      <td>251.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Excel file containing university data\n",
    "file = '../data/universities.xlsx'\n",
    "\n",
    "df = pd.read_excel(file, sheet_name='universities')\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The routine `read_excel()` takes the argument `sheet_name` to\n",
    "specify the sheet that should be read.\n",
    "\n",
    "-   Note that the Python package `xlrd` needs to be installed in order\n",
    "    to read files from Excel 2003 and above.\n",
    "\n",
    "Finally, we often encounter text files with fixed field widths,\n",
    "since this is a commonly used format in older applications\n",
    "(for example, fixed-width files are easy to create in Fortran).\n",
    "To illustrate, the fixed-width variant of our FRED data looks like this:\n",
    "```\n",
    "Year GDP    CPI  UNRATE\n",
    " 1948 2118.5   24     3.8\n",
    " 1949 2106.6 23.8       6\n",
    " 1950 2289.5 24.1     5.2\n",
    " 1951 2473.8   26     3.3\n",
    " 1952 2574.9 26.6       3\n",
    "```\n",
    "You see that the column `Year` occupies the first 5\n",
    "characters, the `GDP` column the next 7 characters, and so on.\n",
    "To read such files, the width (i.e. the number of characters)\n",
    "has to be explicitly specified:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Year     GDP   CPI  UNRATE\n",
       "0  1948  2118.5  24.0     3.8\n",
       "1  1949  2106.6  23.8     6.0\n",
       "2  1950  2289.5  24.1     5.2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year</th>\n      <th>GDP</th>\n      <th>CPI</th>\n      <th>UNRATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1948</td>\n      <td>2118.5</td>\n      <td>24.0</td>\n      <td>3.8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1949</td>\n      <td>2106.6</td>\n      <td>23.8</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1950</td>\n      <td>2289.5</td>\n      <td>24.1</td>\n      <td>5.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File name of FRED data, stored as fixed-width text\n",
    "file = '../data/FRED-fixed.csv'\n",
    "\n",
    "# field widths are passed as list to read_fwf()\n",
    "df = pd.read_fwf(file, widths=[5, 7, 5, 8])\n",
    "df.head(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the `widths` argument accepts a list that contains the\n",
    "number of characters to be used for each field."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "## Pickling\n",
    "\n",
    "A wholly different approach to data I/O is taken by Python's\n",
    "built-in [`pickle`](https://docs.python.org/3/library/pickle.html)\n",
    "module.\n",
    "Almost any Python object can be\n",
    "dumped into a binary file and read back using `pickle.dump()`\n",
    "and `pickle.load()`.\n",
    "\n",
    "The big advantage over other methods\n",
    "is that hierarchies of objects are automatically supported.\n",
    "For example, we can pickle a list containing a `tuple`, a string and a NumPy array:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Pickled data written to /tmp/tmpctc5u3bq/data.bin\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tempfile\n",
    "import os.path\n",
    "\n",
    "# Generate 2d array of integers\n",
    "arr = np.arange(10).reshape((2, -1))\n",
    "tpl = (1, 2, 3)\n",
    "text = 'Pickle is very powerful!'\n",
    "\n",
    "# data: several nested containers and strings\n",
    "data = [tpl, text, arr]\n",
    "\n",
    "# create temporary directory\n",
    "d = tempfile.TemporaryDirectory()\n",
    "# Binary destination file\n",
    "file = os.path.join(d.name, 'data.bin')\n",
    "\n",
    "# print destination file path\n",
    "print(f'Pickled data written to {file}')\n",
    "\n",
    "with open(file, 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can then read back the data as follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4],\n",
       "       [5, 6, 7, 8, 9]])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# load pickle data from above\n",
    "with open(file, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# expand data into its components\n",
    "tpl, text, arr = data\n",
    "arr         # prints previously generated 2d array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The above example introduces a few concepts we have not encountered so far:\n",
    "\n",
    "1.  The built-in function \n",
    "    [`open()`](https://docs.python.org/3/library/functions.html#open)\n",
    "    is used to open files for reading or writing.\n",
    "\n",
    "    -   The second argument indicates whether\n",
    "        a file should be read-only, `r`, or writeable, `w`.\n",
    "    -   The `b` sets the file mode to *binary*, i.e. its contents are *not*\n",
    "        human-readable text.\n",
    "\n",
    "2.  We usually access files using a so-called *context manager*.\n",
    "    A context manager is created via the `with` statement.\n",
    "\n",
    "    A big advantage of using a context manager is that the\n",
    "    file resource made available as `f` in the block following\n",
    "    `with` is automatically cleaned up as soon as the block exits.\n",
    "    This is particularly important when writing data.\n",
    "\n",
    "So why not always use `pickle` to load and store data?\n",
    "\n",
    "1.  Pickling is Python-specific and no other application can process\n",
    "    pickled data.\n",
    "2.  The pickle protocol can change in a newer version of Python,\n",
    "    and you might not be able to read back your old pickled objects.\n",
    "3.  Even worse, because projects such as NumPy and pandas implement\n",
    "    their own pickling routines, you might not even be able\n",
    "    to unpickle old DataFrames when you upgrade to a newer pandas version!\n",
    "4.  `pickle` is not secure: It is possible to construct binary\n",
    "    data that will execute arbitrary code when unpickling, so you\n",
    "    don't want to unpickle data from untrusted sources.\n",
    "5.  Some objects cannot be pickled automatically.\n",
    "    For example, this applies to\n",
    "    any classes defined with Numba or Cython, unless special care\n",
    "    is taken to implement the pickle protocol.\n",
    "\n",
    "\n",
    "`pickle` is great for internal use when you do not need to exchange\n",
    "data with others and have complete control over your computing environment\n",
    "(i.e. you can enforce a specific version of Python and the libraries you are\n",
    "using). For anything else, you should avoid it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-b08fdce2",
   "language": "python",
   "display_name": "PyCharm (python-statistics)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}